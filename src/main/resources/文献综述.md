### 文献综述

随着可移动终端，5G技术，物联网，传感器技术等的发展，所产生的数据正在呈现出几何式增长，人类正逐渐走进大数据时代，面对这些海量数据，传统的信息处理方式很难处理，如何进行收集、储存、检索、分析、应用，是摆在全人类面前的一个问题。

​	1989年，Gartner Group的Howard Dresner首次提出“商业智能”（Business Intelligence）这一术语。商业智能通常被理解为企业中现有的数据转化为知识､帮助企业做出明智的业务经营决策的工具，主要目标是将企业所掌握的的信息转换成竞争优势，提高企业决策能力､决策效率､决策准确性。“大数据”一词流行于2009年，起初成熟于互联网行业，因为互联网行业的数据增长迅速，每两年翻一番，，而目前世界上90%以上的数据是最近几年才产生的。全球互联网公司都意识到“大数据”时代的到来，数据对于企业来说有着重要的意义和价值。如果不能进行很好的分析和提炼，也很难发现大数据背后的价值。要想更好的处理这些数据，首先需要了解这些数据的特点，并针对这些特点提出对应的解决方案。

#### 大数据特征

在现在的IT行业，各个企业对大数据这一概念都有着不同的解读。但大家都普遍认为，大数据有着4V特征，即Volume（大容量）､Variety(种类多)､Velocity(速度快)以及Value（价值密度低）。

Volume是指大数据巨大的数据量与数据完整性。十几年前，由于存储方式､科技手段和分析成本等的限制，使得当时许多数据都无法得到记录和保存。即使是可以保存的信号，也大多采用模拟信号保存，当其转变为数字信号的时候，由于信号的采样和转换，都不可避免存在数据的遗漏与丢失。那么现在，大数据的出现，使得信号得以以最原始的状态保存下来，数据量的大小已不是最重要的，数据的完整性才是最重要的。

Variety意味着要在海量､不同数据来源，以及不同存储介质的数据间发现彼此的关联。在大数据时代，各种设备连成一个整体，需要一个平台在这个整体中担任既是信息的收集者也是信息的传播者的角色，推动了数据量的爆炸式增长。这就必然促使我们要在各种各样的数据中发现数据信息之间的相互关联，把看似无用的信息转变为有效的信息，从而做出正确的判断。

Velocity可以理解为数据的产生的速度快，如果不能快速的处理这些数据那么这些数据的价值就会丢失，这也要求我们在设计平台的时候要考虑满足实时性需求。目前，对于数据智能化和实时性的要求越来越高，比如开车时会查看智能导航仪查询最短路线，吃饭时会了解其他用户对这家餐厅的评价，见到可口的食物会拍照发微博等诸如此类的人与人､人与机器之间的信息交流互动，这些都不可避免带来数据交换。而数据交换的关键是降低延迟，以近乎实时的方式呈献给用户。

大数据特征里最关键的一点，就是Value。这也是我们进行数据分析的理论基础。Value的意思是指大数据的价值密度低。大数据时代数据的价值就像沙子淘金，虽然数据量很大，但里面真正的价值很少。现在的任务就是将这些海量数据，利用云计算､智能化开源实现平台等技术，提取出有价值的信息，将信息转化为知识，发现规律，最终用知识促成正确的决策和行动。

#### 什么是元数据

对于这个海量而多样的数据信息。我们应该怎样高效而快速的进行处理和分析呢？这个时候元数据就应运而生了。元数据被用来定义数据的结构的数据。它汇总了当前数据的基本信息，使我们可以更轻松的查找､使用和重用数据实例。一言以蔽之就是描述数据的数据。在生活中的方方面面，只要有数据存在的地方，就有其数据对应的元数据。因为有元数据的存在，人们才能更好地理解数据，管理数据，更好的挖掘数据的价值。定义好元数据是进行数据分析和管理的前提。



#### 元数据的历史和起源

Metadata Information Partners（现为 The Metadata Co.）的创始人 Jack E. Myers 声称在 1969 年创造了这个词。Myers 于 1986 年为不带连字符的词“元数据”申请了商标。尽管如此，对该词的引用出现在早于迈尔斯的主张的学术论文。在1967 年发表的一篇学术论文中，麻省理工学院教授 David Griffel 和 Stuart McIntosh 将元数据描述为“数据记录的记录”，当发现关于某个主题的书目数据是从离散来源收集时产生的。研究人员得出结论，需要一种“元语言方法”或“元语言”，以使计算机系统能够正确地将这些数据及其上下文解释为其他相关数据。与 Myers 不同，Griffel 和 McIntosh 将“元”视为“数据”的前缀。1964 年，一位名叫 Philip R. Bagley 的计算机科学专业本科生开始撰写他的论文，他在论文中认为“制作复合数据元素”的努力最终取决于“明确关联”到第二个相关数据元素的能力， “我们可以称之为‘元数据元素’。”尽管他的论文被拒绝，但巴格利的工作，包括他对元数据的引用，随后在 1969 年 1 月与美国空军科学研究办公室的合同作为报告出版。

#### 元数据的使用

数据增长速度的加快激发了人们对可从元数据中获得的潜在商业价值的新兴趣。存在各种数据结构，既带来机遇，也带来挑战。元数据管理框架应运而生，元数据管理框架提供了一个组织框架来协调存储在各种系统中的离散数据集。它还提供了描述信息的组织共识，通常分为业务、运营和技术数据。

元数据管理提供了一个组织框架来协调存储在各种系统中的离散数据集。它还提供了描述信息的组织共识，通常分为业务、运营和技术数据。

#### 元数据管理

数据增长速度的加快激发了人们对可从元数据中获得的潜在商业价值的新兴趣。存在各种数据结构，既带来机遇，也带来挑战。元数据管理框架应运而生，元数据管理框架提供了一个组织框架来协调存储在各种系统中的离散数据集。它还提供了描述信息的组织共识，通常分为业务、运营和技术数据。

公司实施元数据管理以筛选旧数据并开发分类法以根据其业务价值对数据进行分类。其中的一个组件是用作元数据存储库（也称为数据字典）的目录或中央数据库。除了对数据进行分类之外，元数据管理策略还用于改进数据分析、制定数据治理策略并建立符合法规的审计跟踪。

元数据管理的核心是使人们能够使用基于Web等用户界面识别特定数据片段的属性。该属性可能是文件名、作者、客户 ID 号等。因此，请求文档的人能够查看和理解数据的不同属性、数据所在的企业系统以及创建这些属性的原因。

截至 2020 年 11 月，Alation、ASG、Alex Solutions、Collibra、Erwin、IBM、Informatica、Oracle、SAP 和 SmartLogic 在 IT 分析公司 Gartner的元数据管理解决方案魔力象限中被列为领先的元数据管理平台供应商。虽然应该收集什么样的数据，没有绝对的标准，但是对大数据开发平台来说，常见的元数据信息应包括：数据的表结构信息，数据的空间存储，读写权限和其他各类统计数据，数据的血缘关系，数据的业务数据。收集元数据信息是为了数据质量管理，虽然这些数据原数据源中也存在，但是业务系统并不适合从原数据源系统中直接读取这些数据信息，业务系统应该和这些功能解耦，使业务系统更加贴近于业务。所以，收集表结构信息，不光是简单的信息汇总，更重要的是从平台管理和业务需求的角度出发来考虑，如何整理和归纳数据，方便系统集成，实现最终的业务价值。数据的空间存储，读写权限和其他各类统计数据应该至少包括：数据占取的底层存储空间，历史记录，审计数据。虽然具体的底层数据管理组件自身也记录着这心信息，但是这些功能并不能直接满足业务的需求，需要通过专门的元数据管理平台统一进行采集，加工和管理。数据的血缘关系信息，指的是数据之间的上下游来源去向关系，利用这些关系，建立起生产这些数据的人物之间的依赖关系，进而辅助调度系统的工作调度，或者用来判断一个错误和失败的任务可能对哪些下游数据造成影响以及对于失败的任务进行恢复。数据的业务属性信息，通常与底层系统自身的运行逻辑无关，多半就需要通过其他手段从外部获取了，这些数据与业务系统强相关。对于这些数据的管理和分析，是元数据管理平台的最重要的功能。

#### 元数据管理平台

##### Apache Atlas

目前市场上的元数据管理工具大致分为 开源和商业。由于现在的互联网企业普遍对元数据管理重视性不高、大多数据仓库体量小以及各行业、企业数据现状复杂不同影响 开源的目前有Apache的Atlas。

Atlas的架构方案应该说相当典型，基本上这类系统大致都会由元数据的收集，存储和查询展示三部分核心组件组成。此外，还会有一个管理后台对整体元数据的采集流程以及元数据格式定义和服务的部署等各项内容进行配置管理。

对应到Atlas的实现上，Atlas通过各种hook/bridge插件来采集几种数据源的元数据信息，通过一套自定义的Type 体系来定义元数据信息的格式，通过搜索引擎对元数据进行全文索引和条件检索，除了自带的UI控制台意外，Atlas还可以通过Rest API的形式对外提供服务。

Atlas的整体设计侧重于数据血缘关系的采集以及表格维度的基本信息和业务属性信息的管理。为了这个目的，Atlas设计了一套通用的Type体系来描述这些信息。主要的Type基础类型包括DataSet和Process，前者用来描述各种数据源本身，后者用来描述一个数据处理的流程，比如一个ETL任务。

Atlas现有的Bridge实现，从数据源的角度来看，主要覆盖了Hive，HBase，HDFS和Kafka，此外还有适配于Sqoop, Storm和Falcon的Bridge，不过这三者更多的是从Process的角度入手，最后落地的数据源还是上述四种数据源。

具体Bridge的实现多半是通过上述底层存储，计算引擎各自流程中的Hook机制来实现的，比如Hive SQL的Post Execute Hook，HBase的Coprocessor等，而采集到的数据则通过Kafka消息队列传输给Atlas Server或者其它订阅者进行消费。

在业务信息管理方面，Atlas通过用户自定义Type 属性信息的方式，让用户可以实现数据的业务信息填写或者对数据打标签等操作，便于后续对数据进行定向过滤检索。

最后，Atlas可以和Ranger配套使用，允许Ranger通过Atlas中用户自定义的数据标签的形式来对数据进行动态授权管理工作，相对于基于路径或者表名/文件名的形式进行静态授权的方式，这种基于标签的方式，有时候可以更加灵活的处理一些特定场景下的权限管理工作。

总体而言，Atlas的实现，从结构原理的角度来说，还算是比较合理的，但从现阶段来看，Atlas的具体实现还比较粗糙，很多功能也是处于可用但并不完善的状态。此外Atlas在数据审计环节做的工作也不多，与整体数据业务流程的集成应用方面的能力也很有限。Atlas项目本身很长时间也都处于Incubator状态，截至2012-12-03，一直都在更新，但是目前功能还不够完善，因此还需要大家一起努力来帮助它的改进。对于一些自研项目或者是一个很好的开始，可以基于Apache Atlas针对自己的业务进行二次开发。

##### Cloudera Navigator Data Management

另外一个比较常见的解决方案是Cloudera CDH发行版中主推的Navigator，相比Atlas而言，Navigator的整体实现更加成熟一些，更像一个完整的解决方案，不过，Navigator并不是开源的。

Navigator的产品定位是数据管理，本质上也是通过管理元数据来管理数据，但周边工具和配套设施相对完善，和Cloudera Manager管理后台的产品集成工作也做得比较彻底。相比Atlas来说，Navigator的整体组件架构也更加复杂一些。

Navigator定位为数据管理，所以对数据的审计管理方面的工作也会做得更多一些，除了采集和管理Hive/Impala等表格的血缘信息，Navigator也可以配置采集包括HDFS的读写操作记录，Yarn/Spark/Pig等作业的运行统计数据在内的信息。Navigator同时还为用户提供了各种统计分析视图和查询管理工具来分析这些数据。

从底层实现来看，Navigator同样通过Hook或着Plugin插件的形式从各种底层系统的运行过程中获取相关信息。但与Atlas不同的是，Navigator的元数据采集传输处理流程并没有把这些信息写入到消息队列中，而是主要通过这些插件写入到相关服务所在的本地Log文件中，然后由Cloudera Manager在每台服务节点上部署的Agent来读取，过滤，分析处理并传输这些信息给审计服务器。

此外Navigator还通过独立的Metadata Server来收集和分析一些非Log来源的元数据信息，并统一对外提供元数据的配置管理服务。用户还可以通过配置Policy策略，让Metadata Server自动基于用户定义的规则，替用户完成数据的Tag标签打标工作，进而提升数据自动化自治管理的能力。

总体而言，Navigator和Cloudera Manger的产品集成工作做得相对完善，如果你使用CDH发行版全家福套件来管理你的集群的话，使用Navigator应该是一个不错的选择。不过，如果是自主管理的集群或者自建的大数据开发平台，深度集成定制的Navigator就很难为你所用了，但无论如何，对于自主开发的元数据管理系统来说，Navigator的整体设计思想也还是值得借鉴的。



#### 元数据管理展望

随着各个公司的业务不断扩展，数据源不断增多。每个业务都是相互独立的，很多工作都要冲头做起，在计算机技术领域现象就是重复的开发工作。二元数据管理平台可以把这些重复的开发工作复用起来，上层业务可以直接基于元数据管理平台已有的功能去实现，这样达成目标的路径更短更高效，对于业务可以做到敏捷开发，对于需求可以做到快速响应。所以元数据管理平台在未来一定可以得到广大企业和组织的应用，如果可以实现一个可以普遍接入的元数据管理平台，在未来一定可以拥有广大的市场。

